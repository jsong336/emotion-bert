{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCb59-1aclGe"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    !pip install tweet_preprocessor\n",
    "    !pip install attrdict\n",
    "    !pip install transformers\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGDbj8F1ckr5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import torch\n",
    "import random \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from attrdict import AttrDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModel , \n",
    "    AdamW, get_linear_schedule_with_warmup)\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "from posixpath import join as pathjoin\n",
    "\n",
    "config_path = '../config/%s.yaml'\n",
    "\n",
    "def check_device_match(device):\n",
    "    if device == 'cuda':\n",
    "        assert torch.cuda.is_available()\n",
    "    return \n",
    "\n",
    "def load_args(module):\n",
    "    with open(config_path % module, 'r') as f:\n",
    "        args = AttrDict(yaml.safe_load(f))\n",
    "\n",
    "    device = args.device\n",
    "    check_device_match(device)\n",
    "    print('device: {}'.format(device))\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0VufwoAckr9"
   },
   "outputs": [],
   "source": [
    "def init_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvRdL6FTckr-"
   },
   "outputs": [],
   "source": [
    "class ZipDataset(Dataset):\n",
    "  def __init__(self, datasets):\n",
    "    super(ZipDataset, self).__init__()\n",
    "    self.keys = list(datasets.keys())\n",
    "    self.values = list(datasets.values()) \n",
    "    self.datasets = datasets\n",
    "    assert all([len(self.values[0]) == len(v) for v in self.values])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.values[0])\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    item = {}\n",
    "    for k, v in self.datasets.items():\n",
    "      item[k] = v[idx]\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iE1rYpT8ckr_"
   },
   "outputs": [],
   "source": [
    "# transformer specific\n",
    "def tokenize_bert_inputs(texts, tokenizer, maxlen=100):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        texts, \n",
    "        return_attention_mask=True, \n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation='longest_first', \n",
    "        max_length=maxlen\n",
    "    )\n",
    "    \n",
    "def _generate_bert_dataset(\n",
    "    X, \n",
    "    y, \n",
    "    tokenizer,\n",
    "    sentence_max_len = 82,\n",
    "    split=None\n",
    "):\n",
    "    if split is None:\n",
    "        X_tk = tokenize_bert_inputs(\n",
    "            X.tolist(), \n",
    "            tokenizer=tokenizer, \n",
    "            maxlen=sentence_max_len\n",
    "        )\n",
    "        dataset = ZipDataset({\n",
    "            'input_ids': Tensor(X_tk['input_ids']).type(torch.int32), \n",
    "            'attention_mask': Tensor(X_tk['attention_mask']).type(torch.int32), \n",
    "            'y_true': Tensor(y).type(torch.float32)\n",
    "        })\n",
    "        return dataset\n",
    "    else:\n",
    "        X1, X2, y1, y2 = train_test_split(\n",
    "            X, y, \n",
    "            test_size=split, \n",
    "            shuffle=False,\n",
    "        )\n",
    "        d1 = _generate_bert_dataset(X1, y1, tokenizer, sentence_max_len, split=None)\n",
    "        d2 = _generate_bert_dataset(X2, y2, tokenizer, sentence_max_len, split=None)\n",
    "        return (d1, d2)\n",
    "\n",
    "def generate_bert_dataset(\n",
    "    dataset_path, \n",
    "    tokenizer,\n",
    "    emotions, \n",
    "    sentence_max_len=82,\n",
    "    split= None\n",
    "):\n",
    "    D = pd.read_csv(dataset_path)\n",
    "    X = D['text'].to_numpy()\n",
    "    y = D[list(emotions)].to_numpy()\n",
    "\n",
    "    return _generate_bert_dataset(\n",
    "        X, y, \n",
    "        tokenizer, \n",
    "        sentence_max_len, \n",
    "        split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2KTQDgCcksA"
   },
   "outputs": [],
   "source": [
    "# models\n",
    "class TransformerEncoderBase(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        encoder, \n",
    "        criterion, \n",
    "        config=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.set_encoder(encoder)\n",
    "        self.criterion = criterion\n",
    "        self.config = config if config else {} # put all model argument except encoder, encoder_dim in the \n",
    "\n",
    "    def unset_encoder(self):\n",
    "        tmp = self.encoder\n",
    "        self.set_encoder(None)\n",
    "        return tmp\n",
    "\n",
    "    def set_encoder(self, encoder):\n",
    "        self.encoder = encoder \n",
    "        self.encoder_dim = encoder.config.hidden_size if encoder else None\n",
    "        return\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.encoder(input_ids, attention_mask,)\n",
    "\n",
    "    def save_pretrained(self, path):\n",
    "        encoder_path = pathjoin(path, 'encoder')\n",
    "        pt_path = pathjoin(path, 'model.pt')\n",
    "        encoder = self.unset_encoder()\n",
    "        encoder.save_pretrained(encoder_path)\n",
    "        torch.save({\n",
    "            'model': self.state_dict(), \n",
    "            'config': {\n",
    "                'encoder': encoder.config.to_dict(), \n",
    "                'criterion': self.criterion.__class__.__name__,\n",
    "                'architecture': str(self), \n",
    "                'module':self.config, \n",
    "            }\n",
    "        }, pt_path)\n",
    "        self.set_encoder(encoder)\n",
    "        return \n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, path):\n",
    "        encoder_path = pathjoin(path, 'encoder')\n",
    "        pt_path = pathjoin(path, 'model.pt')\n",
    "\n",
    "        checkpoint = torch.load(pt_path, map_location=torch.device('cpu'))\n",
    "        config = checkpoint['config']\n",
    "        encoder = AutoModel.from_pretrained(encoder_path)\n",
    "        \n",
    "        model = cls(\n",
    "            encoder=encoder,\n",
    "            criterion = getattr(torch.nn, config['criterion'])(), \n",
    "            **config['module']\n",
    "        )\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        return model\n",
    "\n",
    "    def load_state_dict(self, *args, **kwargs):\n",
    "        encoder = self.unset_encoder()\n",
    "        super().load_state_dict(*args, **kwargs)\n",
    "        self.set_encoder(encoder) \n",
    "        return \n",
    "\n",
    "def check_model_same(m1, m2):\n",
    "    m1_state = m1.state_dict()\n",
    "    m2_state = m2.state_dict()\n",
    "\n",
    "    assert set(m1_state.keys()) == set(m2_state.keys())\n",
    "    \n",
    "    for k in m1_state.keys():\n",
    "        assert torch.equal(m1_state[k], m2_state[k]), '{} mismatch'.format(k)\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-rAKnGIcksB"
   },
   "outputs": [],
   "source": [
    "# train, test, evaluation, metrics\n",
    "def compute_classification_metrics(y_true, proba, threshold):\n",
    "    assert len(y_true) == len(proba), 'y_true and y_pred length mismatch {} {}'.format(len(y_true), len(threshold))\n",
    "    labels=np.array(range(y_true.shape[-1]))\n",
    "\n",
    "    results = {}\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = (proba >= threshold).astype(int)\n",
    "\n",
    "    results[\"accuracy\"] = (y_true == y_pred).mean()\n",
    "    try:\n",
    "      results[\"auc_roc_macro\"] = roc_auc_score(y_true, proba, average='macro')\n",
    "      results[\"auc_roc_micro\"] = roc_auc_score(y_true, proba, average='micro')\n",
    "    except: pass\n",
    "    results[\"macro_precision\"], results[\"macro_recall\"], results[\"macro_f1\"], _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", labels=labels, zero_division=0)\n",
    "    results[\"micro_precision\"], results[\"micro_recall\"], results[\"micro_f1\"], _ = precision_recall_fscore_support(y_true, y_pred, average=\"micro\", labels=labels, zero_division=0)\n",
    "    results[\"weighted_precision\"], results[\"weighted_recall\"], results[\"weighted_f1\"], _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\", labels=labels, zero_division=0)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZMuqfPGcksC"
   },
   "outputs": [],
   "source": [
    "def predict_proba(\n",
    "    model, \n",
    "    dataset, \n",
    "    batch_size=16, \n",
    "    device='cpu', \n",
    "    back_to_cpu=True):\n",
    "\n",
    "  eval_dataloader = DataLoader(\n",
    "      dataset, \n",
    "      batch_size=batch_size, \n",
    "  )\n",
    "\n",
    "  n_batch = 0\n",
    "  proba = []\n",
    "\n",
    "  model.to(device)\n",
    "\n",
    "  for batch in tqdm(eval_dataloader, desc='evaluation', leave=False):\n",
    "    model.eval()\n",
    "    batch = { k:v.to(device) for k, v in batch.items() if k != 'y_true'}\n",
    "\n",
    "    with torch.no_grad():\n",
    "      logits = model(**batch)\n",
    "      logits = logits.cpu().detach().numpy()\n",
    "\n",
    "    p = 1 / (1 + np.exp(-logits))\n",
    "    proba.append(p)\n",
    "\n",
    "    n_batch += 1\n",
    "\n",
    "  if back_to_cpu:\n",
    "    model.cpu()\n",
    "\n",
    "  proba = np.vstack(proba)\n",
    "  return proba\n",
    "\n",
    "def predict_proba_examples(X_tk, model):    \n",
    "    with torch.no_grad():\n",
    "        X_tk = { k:v for k, v in X_tk.items() if k != 'y_true'}\n",
    "        logits = model(**X_tk).numpy()\n",
    "        proba = 1 / (1 + np.exp(-logits))\n",
    "    \n",
    "    return proba\n",
    "\n",
    "def proba_to_emotion(proba, threshold, emotions):\n",
    "  assert proba.shape[-1] == len(emotions), 'emotions and proba mismatch {} vs {}'.format(len(emotions), proba.shape[-1])\n",
    "  emotions = np.array(emotions)\n",
    "\n",
    "  return [list(zip(list(emotions[p >= threshold]),p[p >= threshold])) for p in proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "522k96sucksD"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, \n",
    "             dataset, \n",
    "             batch_size=16, \n",
    "             threshold=0.5,\n",
    "             device='cpu', \n",
    "             sample_ratio=None,\n",
    "             shuffle=False, \n",
    "             back_to_cpu=True):\n",
    "\n",
    "  eval_dataloader = DataLoader(\n",
    "      dataset, \n",
    "      batch_size=batch_size,\n",
    "      shuffle=shuffle,  \n",
    "  )\n",
    "\n",
    "  max_batch = int(len(eval_dataloader) * sample_ratio) \\\n",
    "    if sample_ratio else len(eval_dataloader)\n",
    "  n_batch = 0\n",
    "  total_loss = 0.0\n",
    "  y_true = []\n",
    "  proba = []\n",
    "\n",
    "  model.to(device)\n",
    "\n",
    "  for batch in tqdm(eval_dataloader, desc='evaluation', total=max_batch, leave=False):\n",
    "    model.eval()\n",
    "    batch = { k:v.to(device) for k, v in batch.items() }\n",
    "\n",
    "    with torch.no_grad():\n",
    "      loss_per_batch, logits = model(**batch)\n",
    "      total_loss += loss_per_batch.item()\n",
    "\n",
    "      logits = logits.cpu().detach().numpy()\n",
    "\n",
    "    p = 1 / (1 + np.exp(-logits))\n",
    "    proba.append(p)\n",
    "    y_true.append(batch['y_true'].cpu().detach().numpy())\n",
    "\n",
    "    n_batch += 1\n",
    "    if n_batch >= max_batch:\n",
    "      break\n",
    "\n",
    "  if back_to_cpu:\n",
    "    model.cpu()\n",
    "\n",
    "  proba = np.vstack(proba)\n",
    "  y_true = np.vstack(y_true)\n",
    "  results = {\n",
    "      'loss': total_loss / n_batch, \n",
    "      'trigger_rate': (proba >= threshold).mean(), \n",
    "      **compute_classification_metrics(y_true, proba, threshold)\n",
    "  }\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6s8YiCpcksD"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model, \n",
    "    archive_dir, \n",
    "    model_name, \n",
    "    checkpoint_id=\"null-model\", \n",
    "    metadata=None,\n",
    "    tokenizer=None, \n",
    "    optimizer=None, \n",
    "    scheduler=None,\n",
    "):\n",
    "  # create archive folder\n",
    "  archive_path = pathjoin(archive_dir, model_name)\n",
    "  if not os.path.exists(archive_path):\n",
    "    os.makedirs(archive_path, exist_ok=True)\n",
    "\n",
    "  # create checkpoint folder\n",
    "  checkpoint_dir = pathjoin(archive_path, 'checkpoint-%s' % str(checkpoint_id))\n",
    "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "  # save model in checkpoint\n",
    "  model_to_save = (model.module if hasattr(model, \"module\") else model)\n",
    "  model_to_save.save_pretrained(checkpoint_dir)\n",
    "  if tokenizer is not None:\n",
    "    tokenizer.save_pretrained(checkpoint_dir)\n",
    "  if metadata:\n",
    "    torch.save(metadata, pathjoin(checkpoint_dir, \"meta.bin\"))\n",
    "  if scheduler is not None:\n",
    "    torch.save(scheduler.state_dict(), pathjoin(checkpoint_dir, 'scheduler.pt'))\n",
    "  if optimizer is not None:\n",
    "    torch.save(optimizer.state_dict(), pathjoin(checkpoint_dir, 'optimizer.pt'))\n",
    "\n",
    "  return archive_path\n",
    "\n",
    "def load_from_checkpoint(\n",
    "    archive_dir, \n",
    "    model_name, \n",
    "    checkpoint_id=\"null-model\", \n",
    "    load_tokenizer=False, \n",
    "    load_metadata=True, \n",
    "    load_optimizer=False, \n",
    "    load_model=True,\n",
    "    model_cls=TransformerEncoderBase,\n",
    "    tok_cls=AutoTokenizer\n",
    "):\n",
    "  archive_path = pathjoin(archive_dir, model_name)\n",
    "  checkpoint_dir = pathjoin(archive_path, 'checkpoint-%s' % str(checkpoint_id))\n",
    "\n",
    "  assert os.path.exists(archive_path), archive_path\n",
    "  assert os.path.exists(checkpoint_dir), checkpoint_dir\n",
    "  assert load_model or load_metadata or load_optimizer or load_tokenizer\n",
    "\n",
    "  output = ()\n",
    "\n",
    "  if load_model:\n",
    "    model = getattr(model_cls, 'from_pretrained')(checkpoint_dir)\n",
    "    output += (model, )\n",
    "\n",
    "  if load_tokenizer:\n",
    "    tokenizer = getattr(tok_cls, 'from_pretrained')(checkpoint_dir)\n",
    "    output += (tokenizer, )\n",
    "\n",
    "  if load_metadata or load_optimizer:\n",
    "    metadata = torch.load(pathjoin(checkpoint_dir, 'meta.bin'))\n",
    "    if load_metadata:\n",
    "      output += (metadata, )\n",
    "\n",
    "  if load_optimizer:\n",
    "      grouped_parameters = [{'params': [param for name, param in model.named_parameters() \\\n",
    "                                          if not any(nd in name for nd in ('bias', 'LayerNorm.weight'))]}, \n",
    "                            {'params': [param for name, param in model.named_parameters() \\\n",
    "                                        if any(nd in name for nd in ('bias', 'LayerNorm.weight'))]}]\n",
    "\n",
    "      optimizer = AdamW(grouped_parameters, \n",
    "                    lr=metadata['learning_rate'], \n",
    "                    weight_decay=metadata['weight_decay']) \n",
    "      \n",
    "      scheduler = get_linear_schedule_with_warmup(\n",
    "          optimizer,\n",
    "          num_warmup_steps=int(metadata['train_max_step'] * metadata['warmup_ratio']),\n",
    "          num_training_steps=metadata['train_max_step']\n",
    "      )\n",
    "      optimizer.load_state_dict(torch.load(pathjoin(checkpoint_dir, 'optimizer.pt')))\n",
    "      scheduler.load_state_dict(torch.load(pathjoin(checkpoint_dir, 'scheduler.pt')))\n",
    "\n",
    "      output += (optimizer, scheduler)\n",
    "  return output\n",
    "\n",
    "def get_attrs_from_checkpoints_meta(archive_dir, model_name, attrs, \n",
    "    ignore_null_model=True, \n",
    "    return_df=True,\n",
    "    ):\n",
    "    archive_path = pathjoin(archive_dir, model_name)\n",
    "\n",
    "    results = { k: [] for k in attrs }\n",
    "    results['checkpoint_id'] = []\n",
    "\n",
    "    for dirname in os.listdir(archive_path):\n",
    "        if 'checkpoint' in dirname and \\\n",
    "            (not ignore_null_model or (dirname != 'checkpoint-null-model')):\n",
    "            checkpoint_id = dirname.replace('checkpoint-', \"\")\n",
    "            (metadata,)  = load_from_checkpoint(\n",
    "                archive_dir, \n",
    "                model_name, checkpoint_id, \n",
    "                load_tokenizer=False, \n",
    "                load_metadata=True, \n",
    "                load_optimizer=False, \n",
    "                load_model=False, \n",
    "            )\n",
    "            results['checkpoint_id'].append(checkpoint_id)\n",
    "\n",
    "            for attr in attrs:\n",
    "                attr = attr if attr else None\n",
    "                if attr and '.' in attr:\n",
    "                    outer, inner = attr.split('.')[:2]\n",
    "                    val = metadata[outer][inner]\n",
    "                else:\n",
    "                    val = metadata.get(attr)\n",
    "\n",
    "                results[attr].append(val)\n",
    "\n",
    "    if return_df and ignore_null_model:\n",
    "        results['checkpoint_id'] = [int(k) for k in results['checkpoint_id']]\n",
    "        results = pd.DataFrame(results)\n",
    "        results = results.sort_values(by='checkpoint_id', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "def clear_archive(archive_dir, model_name):\n",
    "  archive_path = pathjoin(archive_dir, model_name)\n",
    "  path_exists = os.path.exists(archive_path)\n",
    "  if path_exists:\n",
    "    shutil.rmtree(archive_path)\n",
    "\n",
    "  os.makedirs(archive_path)\n",
    "  return path_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2K9UmKgUcksG"
   },
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model, \n",
    "    scheduler,\n",
    "    batch, \n",
    "    optimizer, \n",
    "    grad_clip_max=1\n",
    "):\n",
    "  model.train()\n",
    "\n",
    "  loss, logits = model(**batch)\n",
    "  loss.backward()\n",
    "\n",
    "  if grad_clip_max is not None:\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_max)\n",
    "\n",
    "  optimizer.step()\n",
    "  scheduler.step()\n",
    "  model.zero_grad()\n",
    "\n",
    "  return loss.detach().item(), logits\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    metadata,\n",
    "    tokenizer = None, \n",
    "    epochs = 5,\n",
    "    train_batch_size = 16, \n",
    "    val_batch_size = 16, \n",
    "    save_steps = 1e3, \n",
    "    validation_steps = 1e3, \n",
    "    archive_dir = None,\n",
    "    model_name = 'model', # model & archive saved in archive_dir/model_name/..\n",
    "    classification_threshold=0.5, \n",
    "    learning_rate = 1e-3, \n",
    "    grad_clip_max = 1, \n",
    "    weight_decay = 1e-5, \n",
    "    warmup_ratio=0.1,\n",
    "    logging_metrics=None,\n",
    "    optimizer=None, \n",
    "    scheduler=None, \n",
    "    continue_training=False,\n",
    "    device = 'cpu'\n",
    "):\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  # no weight decay on LayerNorm and bias\n",
    "  grouped_parameters = [\n",
    "    {'params': [param for name, param in model.named_parameters() \\\n",
    "               if not any(nd in name for nd in ('bias', 'LayerNorm.weight'))]}, \n",
    "    {'params': [param for name, param in model.named_parameters() \\\n",
    "               if any(nd in name for nd in ('bias', 'LayerNorm.weight'))]}\n",
    "  ]\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size)  \n",
    "  max_step = len(train_dataset) * epochs\n",
    "  metadata['train_max_step'] = max_step\n",
    "\n",
    "  if not continue_training:\n",
    "    # use default b1, b2, eps\n",
    "    optimizer = AdamW(grouped_parameters, \n",
    "                      lr=learning_rate, \n",
    "                      weight_decay=weight_decay) \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(max_step * warmup_ratio),\n",
    "        num_training_steps=max_step\n",
    "    )\n",
    "  else:\n",
    "    assert optimizer is not None\n",
    "    assert scheduler is not None\n",
    "\n",
    "  total_steps = metadata['total_steps'] if continue_training else 0\n",
    "  val_ratio = len(val_dataset) / len(train_dataset)\n",
    "\n",
    "  model.zero_grad() \n",
    "  model.to(device)\n",
    "\n",
    "  save_checkpoint(model, archive_dir, model_name, \n",
    "                  checkpoint_id='null-model', \n",
    "                  metadata=metadata,\n",
    "                  tokenizer=tokenizer, \n",
    "                  optimizer=optimizer, \n",
    "                  scheduler=scheduler)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    print('training epoch %d' % epoch)\n",
    "    for batch in tqdm(train_dataloader, desc=\"Training\", leave=None):\n",
    "      batch = { k:v.to(device) for k, v in batch.items() }\n",
    "      train_step(model, scheduler, batch, optimizer, grad_clip_max)\n",
    "\n",
    "      total_steps += 1 \n",
    "      \n",
    "      if total_steps > 0 and (total_steps % validation_steps == 0 or \\\n",
    "                              total_steps % save_steps == 0):\n",
    "        metadata['val_metrics'] = evaluate(\n",
    "          model, val_dataset, val_batch_size, \n",
    "          classification_threshold, \n",
    "          device=device, back_to_cpu=False)\n",
    "        metadata['tr_metrics'] = evaluate(\n",
    "          model, train_dataset, val_batch_size, \n",
    "          classification_threshold, \n",
    "          device=device, sample_ratio=val_ratio, \n",
    "          back_to_cpu=False)\n",
    "\n",
    "        print('evaluating at step %d' % total_steps)\n",
    "        if logging_metrics is not None:\n",
    "          print('val', { k: v for k, v in metadata['val_metrics'].items() if k in logging_metrics})\n",
    "          print('tr', { k: v for k, v in metadata['tr_metrics'].items() if k in logging_metrics})\n",
    "\n",
    "      if total_steps > 0 and total_steps % save_steps == 0:\n",
    "        print('saving at step %d' % total_steps)\n",
    "        metadata['total_steps'] = total_steps\n",
    "        save_checkpoint(model, archive_dir, model_name, \n",
    "                        optimizer=optimizer, \n",
    "                        scheduler=scheduler, \n",
    "                        checkpoint_id=total_steps, \n",
    "                        metadata=metadata)\n",
    "  model.cpu()\n",
    "  return model, metadata"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "library_utils.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
