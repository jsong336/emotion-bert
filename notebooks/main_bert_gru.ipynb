{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lDBZcPC1yiw6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "%run library_utils.ipynb\n",
        "\n",
        "import os \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import transformers\n",
        "assert transformers.__version__ >= '4.17.'\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModel)\n",
        "from tqdm import tqdm\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "module = 'go-emotion-gru'\n",
        "args = load_args(module)\n",
        "init_seed(args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenizer & Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(args.encoder_name)\n",
        "encoder = AutoModel.from_pretrained(args.encoder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_tk = tokenize_bert_inputs(\n",
        "  ['hello my name is jeongwon', 'what are you?'], \n",
        "  tokenizer, \n",
        "  maxlen=args.sentence_max_len\n",
        ")\n",
        "len(X_tk['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 5.99 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "dataset_path = os.path.join(args.output_dir, args.train_dataset_path)\n",
        "assert os.path.exists(dataset_path)\n",
        "\n",
        "train_dataset, val_dataset = generate_bert_dataset(\n",
        "    dataset_path,     \n",
        "    tokenizer, \n",
        "    emotions = args.emotions, \n",
        "    sentence_max_len = args.sentence_max_len, \n",
        "    split = args.validation_split_from_train\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AA5TgjDEMkgl"
      },
      "outputs": [],
      "source": [
        "class GoEmotionGRUClassifer(TransformerEncoderBase):\n",
        "  def __init__(self, \n",
        "        encoder, \n",
        "        criterion, \n",
        "        seq_len=82,\n",
        "        rnn_hidden = 50,  \n",
        "        rnn_num_layers = 1,\n",
        "        bidirectional=True, \n",
        "        hiddens = None,\n",
        "        dropout_p=0.1, \n",
        "        n_cls:int = 28\n",
        "    ):\n",
        "    config = {\n",
        "        'seq_len': seq_len, \n",
        "        'rnn_hidden': rnn_hidden, \n",
        "        'rnn_num_layers': rnn_num_layers, \n",
        "        'bidirectional': bidirectional, \n",
        "        'hiddens':  [50] if hiddens is None else hiddens, \n",
        "        'dropout_p': dropout_p, \n",
        "        'n_cls': n_cls\n",
        "    }\n",
        "    super().__init__(encoder, criterion, config)\n",
        "\n",
        "    # layers\n",
        "    self.encoder = encoder\n",
        "    self.gru = nn.GRU(\n",
        "        input_size= self.encoder_dim, \n",
        "        hidden_size = rnn_hidden, \n",
        "        batch_first = True, \n",
        "        bidirectional = bidirectional\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    # full connected\n",
        "    fcs = []\n",
        "    in_feature = (int(bidirectional) + 1) * rnn_hidden\n",
        "    for h in self.hiddens:\n",
        "      fcs.append(nn.Linear(in_feature, h))\n",
        "      fcs.append(nn.ReLU())\n",
        "      in_feature = h    \n",
        "    \n",
        "    # final layer \n",
        "    fcs.append(nn.Linear(in_feature, n_cls))\n",
        "    self.fcs = nn.Sequential(*fcs)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, y_true=None):\n",
        "    encoder_output = super().forward(input_ids, attention_mask)\n",
        "    contextual_emb = encoder_output['last_hidden_state']\n",
        "\n",
        "    output, _ = self.gru(contextual_emb)\n",
        "    output = output[:, -1, :]\n",
        "    z = self.dropout(output) \n",
        "    logits = self.fcs(z)\n",
        "\n",
        "    if not (y_true is None):\n",
        "      loss = self.criterion(logits, y_true)\n",
        "      return (loss, logits)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GoEmotionPoolClassifer(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (criterion): BCEWithLogitsLoss()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fcs): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=50, out_features=27, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_go_emotion_gru(args, encoder):\n",
        "    return GoEmotionPoolClassifer(\n",
        "        encoder, \n",
        "        seq_len=args.sentence_max_len,\n",
        "        rnn_hidden=args.hidden, \n",
        "        rnn_num_layer = args.rnn_num_layers, \n",
        "        bidirectional=args.bidirectional, \n",
        "        hiddens = args.fc_hiddens, \n",
        "        dropout_p = args.dropout_p, \n",
        "        n_cls = len(args.emotions)\n",
        "    )\n",
        "\n",
        "model = create_go_emotion_gru(args, encoder)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def proba_on_examples(texts, model):\n",
        "    X_tk = tokenize_bert_inputs(\n",
        "        texts, tokenizer, maxlen = args.sentence_max_len\n",
        "    )\n",
        "    X_tk['input_ids'] = Tensor(X_tk['input_ids']).type(torch.int32)\n",
        "    X_tk['attention_mask'] = Tensor(X_tk['attention_mask']).type(torch.int32)\n",
        "    proba = predict_proba_examples(X_tk, model)\n",
        "    return proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('admiration', 0.41870236), ('amusement', 0.45818296), ('anger', 0.49008417)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "proba = proba_on_examples(['hello my name is jeongwon', 'nice to meet you!'], model)\n",
        "proba_to_emotion(\n",
        "    proba,\n",
        "    args.classification_threshold, \n",
        "    args.emotions, \n",
        ")[0][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPJa_quWJ0DI",
        "outputId": "a1fd619c-64e1-4436-b29d-cbfaf3c9114b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.044444444444444446,\n",
              " 'macro_precision': 0.044444444444444446,\n",
              " 'macro_recall': 0.14814814814814814,\n",
              " 'macro_f1': 0.0670194003527337,\n",
              " 'micro_precision': 0.044444444444444446,\n",
              " 'micro_recall': 1.0,\n",
              " 'micro_f1': 0.0851063829787234,\n",
              " 'weighted_precision': 0.3333333333333333,\n",
              " 'weighted_recall': 1.0,\n",
              " 'weighted_f1': 0.49206349206349215}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "proba = predict_proba_examples(val_dataset[:5], model)\n",
        "y_true = val_dataset[:5]['y_true'].numpy()\n",
        "compute_classification_metrics(y_true, proba, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WtKhHAYXLG6",
        "outputId": "44940168-829f-46b0-adc8-4df8b0045cc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'loss': 0.7004973216184939,\n",
              " 'trigger_rate': 1.0,\n",
              " 'accuracy': 0.04695688599307007,\n",
              " 'macro_precision': 0.04695688599307007,\n",
              " 'macro_recall': 1.0,\n",
              " 'macro_f1': 0.0882997470479051,\n",
              " 'micro_precision': 0.04695688599307007,\n",
              " 'micro_recall': 1.0,\n",
              " 'micro_f1': 0.0897016613029486,\n",
              " 'weighted_precision': 0.0643399480933103,\n",
              " 'weighted_recall': 1.0,\n",
              " 'weighted_f1': 0.11955701106465137}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    model, \n",
        "    val_dataset, \n",
        "    batch_size = args.eval_batch_size, \n",
        "    threshold = args.classification_threshold, \n",
        "    device = args.device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = create_go_emotion_gru(args, encoder)\n",
        "_ = save_checkpoint(\n",
        "    model, \n",
        "    args.output_dir, \n",
        "    model_name='testmodel',\n",
        "    metadata=args\n",
        ")\n",
        "\n",
        "model_copy, _ = load_from_checkpoint(\n",
        "    args.output_dir,\n",
        "    model_name='testmodel',\n",
        "    checkpoint_id='null-model', \n",
        "    model_cls=GoEmotionPoolClassifer\n",
        ")\n",
        "\n",
        "check_model_same(model, model_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# clear_archive(args.output_dir, args.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dumps\\anaconda3\\envs\\emotion-detection\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello\n",
            "training epoch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  49%|████▉     | 3005/6101 [00:48<12:36,  4.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 3000\n",
            "{'macro_precision': 0.03916243040566626, 'macro_recall': 0.49321678434501776, 'macro_f1': 0.047193015026207964}\n",
            "saving at step 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  98%|█████████▊| 6003/6101 [01:37<00:23,  4.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 6000\n",
            "{'macro_precision': 0.002095977877644066, 'macro_recall': 0.037037037037037035, 'macro_f1': 0.00396743314832052}\n",
            "saving at step 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6101/6101 [01:38<00:00, 61.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  48%|████▊     | 2900/6101 [00:46<12:51,  4.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 9000\n",
            "{'macro_precision': 0.0, 'macro_recall': 0.0, 'macro_f1': 0.0}\n",
            "saving at step 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  97%|█████████▋| 5904/6101 [01:34<00:47,  4.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 12000\n",
            "{'macro_precision': 0.0, 'macro_recall': 0.0, 'macro_f1': 0.0}\n",
            "saving at step 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6101/6101 [01:37<00:00, 62.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  46%|████▌     | 2791/6101 [00:39<00:46, 71.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 15000\n",
            "{'macro_precision': 0.0, 'macro_recall': 0.0, 'macro_f1': 0.0}\n",
            "saving at step 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  95%|█████████▌| 5801/6101 [01:34<01:15,  3.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 18000\n",
            "{'macro_precision': 0.0, 'macro_recall': 0.0, 'macro_f1': 0.0}\n",
            "saving at step 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6101/6101 [01:39<00:00, 61.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  44%|████▍     | 2703/6101 [00:45<14:59,  3.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 21000\n",
            "{'macro_precision': 0.054246165357276464, 'macro_recall': 0.002457270003201142, 'macro_f1': 0.004597415972211029}\n",
            "saving at step 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  93%|█████████▎| 5699/6101 [01:36<01:58,  3.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 24000\n",
            "{'macro_precision': 0.07957233689596498, 'macro_recall': 0.06681908705666403, 'macro_f1': 0.07249770679586148}\n",
            "saving at step 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6101/6101 [01:42<00:00, 59.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  43%|████▎     | 2602/6101 [00:43<14:45,  3.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 27000\n",
            "{'macro_precision': 0.11856450611110156, 'macro_recall': 0.08664715537240035, 'macro_f1': 0.09150671090514927}\n",
            "saving at step 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  92%|█████████▏| 5596/6101 [01:34<02:29,  3.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 30000\n",
            "{'macro_precision': 0.14216222918612698, 'macro_recall': 0.11133764910919053, 'macro_f1': 0.11966022935498678}\n",
            "saving at step 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6101/6101 [01:42<00:00, 59.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  41%|████      | 2494/6101 [00:35<00:51, 70.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 33000\n",
            "{'macro_precision': 0.1740575934838749, 'macro_recall': 0.11948390728426023, 'macro_f1': 0.12470979685692794}\n",
            "saving at step 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|█████████ | 5495/6101 [01:32<02:31,  4.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 36000\n",
            "{'macro_precision': 0.2174040216642051, 'macro_recall': 0.12740190374117585, 'macro_f1': 0.14349548291920508}\n",
            "saving at step 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6101/6101 [01:41<00:00, 60.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  39%|███▉      | 2399/6101 [00:40<14:50,  4.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 39000\n",
            "{'macro_precision': 0.24208676827305095, 'macro_recall': 0.1444662653997408, 'macro_f1': 0.1634172999274588}\n",
            "saving at step 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  88%|████████▊ | 5396/6101 [01:28<02:50,  4.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 42000\n",
            "{'macro_precision': 0.2427148526809242, 'macro_recall': 0.14810749372551787, 'macro_f1': 0.16890591181697268}\n",
            "saving at step 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6101/6101 [01:38<00:00, 61.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  38%|███▊      | 2300/6101 [00:38<11:21,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating at step 45000\n",
            "{'macro_precision': 0.3479965672383879, 'macro_recall': 0.15639295652766677, 'macro_f1': 0.18544461725220285}\n",
            "saving at step 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|█████▉    | 3633/6101 [00:58<00:36, 67.27it/s]"
          ]
        }
      ],
      "source": [
        "model = create_go_emotion_gru(args, encoder)\n",
        "model, metadata = train(\n",
        "    model, \n",
        "    train_dataset, \n",
        "    val_dataset, \n",
        "    dict(args), \n",
        "    tokenizer, \n",
        "    epochs=args.train_epochs, \n",
        "    train_batch_size = args.train_batch_size, \n",
        "    val_batch_size = args.eval_batch_size, \n",
        "    save_steps = args.save_steps, \n",
        "    validation_steps= args.validation_steps, \n",
        "    archive_dir = args.output_dir, \n",
        "    model_name = args.model_name, \n",
        "    classification_threshold = args.classification_threshold, \n",
        "    learning_rate = args.learning_rate, \n",
        "    grad_clip_max = args.grad_clip_max, \n",
        "    weight_decay = args.weight_decay, \n",
        "    warmup_ratio = args.warmup_ratio, \n",
        "    logging_metrics= ['macro_f1', 'macro_precision', 'macro_recall'],\n",
        "    continue_training=False,\n",
        "    device = args.device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = get_attrs_from_checkpoints_meta(args.output_dir, args.model_name, ['tr_loss', 'val_metrics'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "proba = predict_proba(\n",
        "    model, \n",
        "    val_dataset, \n",
        "    batch_size = args.eval_batch_size, \n",
        "    device = args.device\n",
        ")\n",
        "y_true = val_dataset[:]['y_true'].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roc_auc_score(y_true, proba, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "for i, emt in enumerate(args.emotions):\n",
        "    fpr, tpr, _ = roc_curve(y_true[:, i], proba[:, i])\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.title(emt)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "proba_to_emotion(\n",
        "    proba_on_examples([\n",
        "        'fuck cloud', \n",
        "        'yeet'\n",
        "    ], model), \n",
        "    0.4, \n",
        "    args.emotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of bert-tf",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
